// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: urls.sql

package database

import (
	"context"
	"database/sql"

	"github.com/google/uuid"
	"github.com/lib/pq"
	"github.com/sqlc-dev/pqtype"
)

const countURLs = `-- name: CountURLs :one
SELECT COUNT(*) FROM urls
`

func (q *Queries) CountURLs(ctx context.Context) (int64, error) {
	row := q.db.QueryRowContext(ctx, countURLs)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const countURLsByStatus = `-- name: CountURLsByStatus :one
SELECT COUNT(*) FROM urls WHERE status = $1
`

func (q *Queries) CountURLsByStatus(ctx context.Context, status string) (int64, error) {
	row := q.db.QueryRowContext(ctx, countURLsByStatus, status)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const createURL = `-- name: CreateURL :one
INSERT INTO urls (
    url, frequency, status, max_retries, timeout, rate_limit, 
    user_agent, parser_config, next_scrape_at
) VALUES (
    $1, $2, $3, $4, $5, $6, $7, $8, $9
) RETURNING id, url, frequency, last_scraped_at, next_scrape_at, status, retry_count, max_retries, parser_config, user_agent, timeout, rate_limit, created_at, updated_at, deleted_at
`

type CreateURLParams struct {
	Url          string
	Frequency    string
	Status       string
	MaxRetries   int32
	Timeout      int32
	RateLimit    int32
	UserAgent    sql.NullString
	ParserConfig pqtype.NullRawMessage
	NextScrapeAt sql.NullTime
}

func (q *Queries) CreateURL(ctx context.Context, arg CreateURLParams) (Url, error) {
	row := q.db.QueryRowContext(ctx, createURL,
		arg.Url,
		arg.Frequency,
		arg.Status,
		arg.MaxRetries,
		arg.Timeout,
		arg.RateLimit,
		arg.UserAgent,
		arg.ParserConfig,
		arg.NextScrapeAt,
	)
	var i Url
	err := row.Scan(
		&i.ID,
		&i.Url,
		&i.Frequency,
		&i.LastScrapedAt,
		&i.NextScrapeAt,
		&i.Status,
		&i.RetryCount,
		&i.MaxRetries,
		&i.ParserConfig,
		&i.UserAgent,
		&i.Timeout,
		&i.RateLimit,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.DeletedAt,
	)
	return i, err
}

const getURLByID = `-- name: GetURLByID :one
SELECT id, url, frequency, last_scraped_at, next_scrape_at, status, retry_count, max_retries, parser_config, user_agent, timeout, rate_limit, created_at, updated_at, deleted_at FROM urls WHERE id = $1
`

func (q *Queries) GetURLByID(ctx context.Context, id uuid.UUID) (Url, error) {
	row := q.db.QueryRowContext(ctx, getURLByID, id)
	var i Url
	err := row.Scan(
		&i.ID,
		&i.Url,
		&i.Frequency,
		&i.LastScrapedAt,
		&i.NextScrapeAt,
		&i.Status,
		&i.RetryCount,
		&i.MaxRetries,
		&i.ParserConfig,
		&i.UserAgent,
		&i.Timeout,
		&i.RateLimit,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.DeletedAt,
	)
	return i, err
}

const getURLsByIDs = `-- name: GetURLsByIDs :many
SELECT id, url, frequency, last_scraped_at, next_scrape_at, status, retry_count, max_retries, parser_config, user_agent, timeout, rate_limit, created_at, updated_at, deleted_at FROM urls WHERE id = ANY($1::uuid[])
`

func (q *Queries) GetURLsByIDs(ctx context.Context, dollar_1 []uuid.UUID) ([]Url, error) {
	rows, err := q.db.QueryContext(ctx, getURLsByIDs, pq.Array(dollar_1))
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []Url
	for rows.Next() {
		var i Url
		if err := rows.Scan(
			&i.ID,
			&i.Url,
			&i.Frequency,
			&i.LastScrapedAt,
			&i.NextScrapeAt,
			&i.Status,
			&i.RetryCount,
			&i.MaxRetries,
			&i.ParserConfig,
			&i.UserAgent,
			&i.Timeout,
			&i.RateLimit,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.DeletedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getURLsByStatus = `-- name: GetURLsByStatus :many
SELECT id, url, frequency, last_scraped_at, next_scrape_at, status, retry_count, max_retries, parser_config, user_agent, timeout, rate_limit, created_at, updated_at, deleted_at FROM urls 
WHERE status = $1 
ORDER BY created_at DESC 
LIMIT $2 OFFSET $3
`

type GetURLsByStatusParams struct {
	Status string
	Limit  int32
	Offset int32
}

func (q *Queries) GetURLsByStatus(ctx context.Context, arg GetURLsByStatusParams) ([]Url, error) {
	rows, err := q.db.QueryContext(ctx, getURLsByStatus, arg.Status, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []Url
	for rows.Next() {
		var i Url
		if err := rows.Scan(
			&i.ID,
			&i.Url,
			&i.Frequency,
			&i.LastScrapedAt,
			&i.NextScrapeAt,
			&i.Status,
			&i.RetryCount,
			&i.MaxRetries,
			&i.ParserConfig,
			&i.UserAgent,
			&i.Timeout,
			&i.RateLimit,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.DeletedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getURLsForImmediateScraping = `-- name: GetURLsForImmediateScraping :many
SELECT id, url, frequency, last_scraped_at, next_scrape_at, status, retry_count, max_retries, parser_config, user_agent, timeout, rate_limit, created_at, updated_at, deleted_at FROM urls 
WHERE next_scrape_at <= $1 
AND status IN ('pending', 'retry')
ORDER BY next_scrape_at ASC 
LIMIT $2
`

type GetURLsForImmediateScrapingParams struct {
	NextScrapeAt sql.NullTime
	Limit        int32
}

func (q *Queries) GetURLsForImmediateScraping(ctx context.Context, arg GetURLsForImmediateScrapingParams) ([]Url, error) {
	rows, err := q.db.QueryContext(ctx, getURLsForImmediateScraping, arg.NextScrapeAt, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []Url
	for rows.Next() {
		var i Url
		if err := rows.Scan(
			&i.ID,
			&i.Url,
			&i.Frequency,
			&i.LastScrapedAt,
			&i.NextScrapeAt,
			&i.Status,
			&i.RetryCount,
			&i.MaxRetries,
			&i.ParserConfig,
			&i.UserAgent,
			&i.Timeout,
			&i.RateLimit,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.DeletedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getURLsScheduledForScraping = `-- name: GetURLsScheduledForScraping :many
SELECT id, url, frequency, last_scraped_at, next_scrape_at, status, retry_count, max_retries, parser_config, user_agent, timeout, rate_limit, created_at, updated_at, deleted_at FROM urls 
WHERE next_scrape_at BETWEEN $1 AND $2 
AND status IN ('pending', 'retry')
ORDER BY next_scrape_at ASC 
LIMIT $3
`

type GetURLsScheduledForScrapingParams struct {
	NextScrapeAt   sql.NullTime
	NextScrapeAt_2 sql.NullTime
	Limit          int32
}

func (q *Queries) GetURLsScheduledForScraping(ctx context.Context, arg GetURLsScheduledForScrapingParams) ([]Url, error) {
	rows, err := q.db.QueryContext(ctx, getURLsScheduledForScraping, arg.NextScrapeAt, arg.NextScrapeAt_2, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []Url
	for rows.Next() {
		var i Url
		if err := rows.Scan(
			&i.ID,
			&i.Url,
			&i.Frequency,
			&i.LastScrapedAt,
			&i.NextScrapeAt,
			&i.Status,
			&i.RetryCount,
			&i.MaxRetries,
			&i.ParserConfig,
			&i.UserAgent,
			&i.Timeout,
			&i.RateLimit,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.DeletedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const incrementRetryCount = `-- name: IncrementRetryCount :exec
UPDATE urls SET retry_count = retry_count + 1, updated_at = NOW() WHERE id = $1
`

func (q *Queries) IncrementRetryCount(ctx context.Context, id uuid.UUID) error {
	_, err := q.db.ExecContext(ctx, incrementRetryCount, id)
	return err
}

const listURLs = `-- name: ListURLs :many
SELECT id, url, frequency, last_scraped_at, next_scrape_at, status, retry_count, max_retries, parser_config, user_agent, timeout, rate_limit, created_at, updated_at, deleted_at FROM urls ORDER BY created_at DESC LIMIT $1 OFFSET $2
`

type ListURLsParams struct {
	Limit  int32
	Offset int32
}

func (q *Queries) ListURLs(ctx context.Context, arg ListURLsParams) ([]Url, error) {
	rows, err := q.db.QueryContext(ctx, listURLs, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []Url
	for rows.Next() {
		var i Url
		if err := rows.Scan(
			&i.ID,
			&i.Url,
			&i.Frequency,
			&i.LastScrapedAt,
			&i.NextScrapeAt,
			&i.Status,
			&i.RetryCount,
			&i.MaxRetries,
			&i.ParserConfig,
			&i.UserAgent,
			&i.Timeout,
			&i.RateLimit,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.DeletedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const resetRetryCount = `-- name: ResetRetryCount :exec
UPDATE urls SET retry_count = 0, updated_at = NOW() WHERE id = $1
`

func (q *Queries) ResetRetryCount(ctx context.Context, id uuid.UUID) error {
	_, err := q.db.ExecContext(ctx, resetRetryCount, id)
	return err
}

const updateLastScrapedTime = `-- name: UpdateLastScrapedTime :exec
UPDATE urls SET last_scraped_at = $2, updated_at = NOW() WHERE id = $1
`

type UpdateLastScrapedTimeParams struct {
	ID            uuid.UUID
	LastScrapedAt sql.NullTime
}

func (q *Queries) UpdateLastScrapedTime(ctx context.Context, arg UpdateLastScrapedTimeParams) error {
	_, err := q.db.ExecContext(ctx, updateLastScrapedTime, arg.ID, arg.LastScrapedAt)
	return err
}

const updateNextScrapeTime = `-- name: UpdateNextScrapeTime :exec
UPDATE urls SET next_scrape_at = $2, updated_at = NOW() WHERE id = $1
`

type UpdateNextScrapeTimeParams struct {
	ID           uuid.UUID
	NextScrapeAt sql.NullTime
}

func (q *Queries) UpdateNextScrapeTime(ctx context.Context, arg UpdateNextScrapeTimeParams) error {
	_, err := q.db.ExecContext(ctx, updateNextScrapeTime, arg.ID, arg.NextScrapeAt)
	return err
}

const updateURLStatus = `-- name: UpdateURLStatus :exec
UPDATE urls SET status = $2, updated_at = NOW() WHERE id = $1
`

type UpdateURLStatusParams struct {
	ID     uuid.UUID
	Status string
}

func (q *Queries) UpdateURLStatus(ctx context.Context, arg UpdateURLStatusParams) error {
	_, err := q.db.ExecContext(ctx, updateURLStatus, arg.ID, arg.Status)
	return err
}
