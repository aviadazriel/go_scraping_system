# Database Package

This package provides PostgreSQL database connectivity for the scraping microservices system using **sqlc** for type-safe SQL operations.

## Technology Choice

We use **sqlc** instead of GORM because:
- **Type Safety**: Compile-time SQL validation
- **Performance**: No ORM overhead
- **Explicit**: You see exactly what SQL runs
- **Consistent**: All services use the same approach
- **Maintainable**: SQL and Go code in sync

## Architecture

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Services      │    │  Database       │    │  sqlc Generated │
│   (URL Manager) │───►│  Connection     │───►│  Queries        │
│                 │    │  (pkg/database) │    │  (internal/db)  │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## Components

### `PostgresDB`
- **Purpose**: Simple database connection wrapper
- **Features**:
  - **Connection pooling** configuration
  - **Health checks** and monitoring
  - **Statistics** collection
  - **sqlc integration** via `*sql.DB`

### `internal/database/` (sqlc-generated)
- **Purpose**: Type-safe SQL queries
- **Features**:
  - **Compile-time SQL validation**
  - **Type-safe models** and queries
  - **Transaction support**
  - **Generated from SQL files**

## Usage

### Database Connection
```go
// Create database connection
db, err := database.NewPostgresDB(cfg, log)
if err != nil {
    log.Fatalf("Failed to connect to database: %v", err)
}
defer db.Close()

// Get sqlc queries
queries := database.New(db.GetDB())

// Use in repositories
urlRepo := repositories.NewURLRepository(queries, log)
```

### Repository Pattern
```go
// Repository uses sqlc queries
type URLRepositoryImpl struct {
    db     *database.Queries  // sqlc-generated
    logger *logrus.Logger
}

func (r *URLRepositoryImpl) GetURLByID(ctx context.Context, id uuid.UUID) (*database.Url, error) {
    url, err := r.db.GetURLByID(ctx, id)
    if err != nil {
        return nil, err
    }
    return &url, nil
}
```

## SQL Queries

### SQL Files (`sql/queries/`)
```sql
-- name: GetURLByID :one
SELECT * FROM urls WHERE id = $1;

-- name: GetURLsScheduledForScraping :many
SELECT * FROM urls 
WHERE next_scrape_at BETWEEN $1 AND $2 
AND status IN ('pending', 'retry')
ORDER BY next_scrape_at ASC 
LIMIT $3;
```

### Generated Go Code
```go
// Auto-generated by sqlc
func (q *Queries) GetURLByID(ctx context.Context, id uuid.UUID) (Url, error) {
    // Implementation generated from SQL
}

func (q *Queries) GetURLsScheduledForScraping(ctx context.Context, arg GetURLsScheduledForScrapingParams) ([]Url, error) {
    // Implementation generated from SQL
}
```

## Configuration

### Database Settings
```yaml
database:
  host: "localhost"
  port: 5432
  name: "scraping_db"
  user: "scraping_user"
  password: "scraping_password"
  max_open_conns: 25
  max_idle_conns: 5
  conn_max_lifetime: "5m"
```

### Connection Pool
```go
db.SetMaxOpenConns(cfg.Database.MaxOpenConns)    // 25
db.SetMaxIdleConns(cfg.Database.MaxIdleConns)    // 5
db.SetConnMaxLifetime(cfg.Database.ConnMaxLifetime) // 5m
```

## Database Schema

### URLs Table
```sql
CREATE TABLE urls (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    url TEXT NOT NULL,
    frequency TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'pending',
    next_scrape_at TIMESTAMP,
    last_scraped_at TIMESTAMP,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    parser_config JSONB,
    user_agent TEXT,
    timeout INTEGER DEFAULT 30,
    rate_limit INTEGER DEFAULT 1000,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    deleted_at TIMESTAMP
);
```

## Migration Management

### Using Goose
```bash
# Run migrations
make migrate

# Create new migration
make migrate-create name=add_urls_table

# Rollback
make migrate-rollback
```

### Migration Files
```sql
-- 001_create_urls_table.sql
CREATE TABLE urls (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    url TEXT NOT NULL,
    -- ... other columns
);

-- 002_add_indexes.sql
CREATE INDEX idx_urls_status ON urls(status);
CREATE INDEX idx_urls_next_scrape ON urls(next_scrape_at);
```

## Error Handling

### Connection Errors
```go
if err := db.HealthCheck(ctx); err != nil {
    log.WithError(err).Error("Database health check failed")
    // Handle connection issues
}
```

### Query Errors
```go
url, err := queries.GetURLByID(ctx, urlID)
if err != nil {
    if err == sql.ErrNoRows {
        return nil, fmt.Errorf("URL not found: %w", err)
    }
    return nil, fmt.Errorf("database error: %w", err)
}
```

## Performance

### Connection Pooling
- **Max Open Connections**: 25 (configurable)
- **Max Idle Connections**: 5 (configurable)
- **Connection Lifetime**: 5 minutes (configurable)

### Query Optimization
- **Indexes** on frequently queried columns
- **Prepared statements** via sqlc
- **Efficient joins** and filtering

## Monitoring

### Health Checks
```go
// Check database connectivity
err := db.HealthCheck(ctx)
if err != nil {
    // Alert or retry
}
```

### Statistics
```go
stats := db.GetStats()
log.WithFields(logrus.Fields{
    "open_connections": stats["open_connections"],
    "in_use":          stats["in_use"],
    "idle":            stats["idle"],
}).Info("Database statistics")
```

## Best Practices

### 1. **Use Transactions**
```go
tx, err := db.BeginTx(ctx, nil)
if err != nil {
    return err
}
defer tx.Rollback()

queries := database.New(tx)
// ... perform operations

return tx.Commit()
```

### 2. **Context Usage**
```go
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
defer cancel()

url, err := queries.GetURLByID(ctx, urlID)
```

### 3. **Error Handling**
```go
if err != nil {
    if errors.Is(err, sql.ErrNoRows) {
        return nil, ErrNotFound
    }
    return nil, fmt.Errorf("database error: %w", err)
}
```

### 4. **Connection Management**
```go
defer db.Close() // Always close connections
```

## Testing

### Unit Tests
```go
// Mock sqlc queries for testing
type MockQueries struct {
    // Mock implementations
}

func TestURLRepository(t *testing.T) {
    mockQueries := &MockQueries{}
    repo := repositories.NewURLRepository(mockQueries, log)
    // ... test logic
}
```

### Integration Tests
```go
// Use real database for integration tests
db, err := database.NewPostgresDB(cfg, log)
queries := database.New(db.GetDB())
// ... test with real database
```

## Troubleshooting

### Common Issues

#### 1. **Connection Failures**
- Check database credentials
- Verify network connectivity
- Check connection pool settings

#### 2. **Query Performance**
- Review SQL execution plans
- Add appropriate indexes
- Monitor query statistics

#### 3. **Migration Issues**
- Check migration order
- Verify SQL syntax
- Review constraint conflicts

### Debug Commands
```bash
# Check database connectivity
psql -h localhost -U scraping_user -d scraping_db

# Check connection pool
SELECT * FROM pg_stat_activity;

# Monitor slow queries
SELECT query, mean_time FROM pg_stat_statements ORDER BY mean_time DESC;
``` 