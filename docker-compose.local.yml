services:
  # Kafka (Zookeeper + Kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: scraping_zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scraper-network

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: scraping_kafka
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "9092:9092"
      - "9101:9101"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - scraper-network

  # Kafka UI (Optional - for monitoring)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: scraping_kafka_ui
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    ports:
      - "8080:8080"
    networks:
      - scraper-network

  # URL Manager Service
  url-manager:
    build:
      context: .
      dockerfile: services/url-manager/Dockerfile
    container_name: scraping_url_manager
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      # Database configuration - use local database
      DATABASE_URL: postgres://scraper:scraper@host.docker.internal:5432/scraping_db?sslmode=disable
      
      # Kafka configuration
      KAFKA_BROKERS: kafka:29092
      
      # Logging
      LOG_LEVEL: info
      
      # Timezone
      TZ: UTC
    ports:
      - "8081:8081"
    volumes:
      - ./configs:/app/configs:ro
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - scraper-network

  # API Gateway Service
  api-gateway:
    build:
      context: .
      dockerfile: services/api-gateway/Dockerfile
    container_name: scraping_api_gateway
    restart: unless-stopped
    depends_on:
      url-manager:
        condition: service_started
    environment:
      # Database configuration - use local database
      DATABASE_URL: postgres://scraper:scraper@host.docker.internal:5432/scraping_db?sslmode=disable
      
      # Kafka configuration
      KAFKA_BROKERS: kafka:29092
      
      # Logging
      LOG_LEVEL: info
      
      # Timezone
      TZ: UTC
    ports:
      - "8082:8080"
    volumes:
      - ./configs:/app/configs:ro
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - scraper-network

volumes:
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local

networks:
  scraper-network:
    driver: bridge 